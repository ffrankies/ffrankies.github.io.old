<h3>Experiment 3 | Teaching Computers</h3>
<p>Welcome once again, to <strong>ffrankie's laboratory</strong>!
It's been quite a while since we at the lab have had the time to
write about our digital adventures. And so, here is a quick
run-down of what's been going on with the site revamp, before we
get to the main story of this post. First, the site revamp is
basically done. As you have maybe noticed, the color schemes for
the individual pages have been changed, and our homepage looks
slightly more professional. We say 'basically' because there are
still a few things to iron out. There are slight display issues in
some browsers, and with certain screen sizes, and a few more
stylistic changes to be done. All this will happen based on time
availability. Secondly, after playing around with animations in
CSS, we have come to the conclusion that they are quite a pain to
implement, and tend to be super distracting. For that reason, they
will most likely not make a big appearance on the site. If we ever
get enough free time, however, there will be a section dedicated to
trying out different animations, kinda like our current gallery
page.<br>
<br>
<br>
Okay, now that that's out of the way, it's time for the main
shebang, as my history professor would call it. Teaching computers,
although an even better title would be how to make a computer
learn. The ability for a computer to learn is something that one
would think we are still far away from achieving. After all, Word
still freezes much too often for everyone's comfort, and we still
haven't figured out how to download pizza. However, the fact of the
matter is that computers CAN learn - and have been doing so for
ages. And, just in case this piece of news has got you building an
off-the grid bunker in the middle of nowhere, we would like to
assure you that this prospect is nowhere near as scary as some
would think. Not yet, at least.<br>
<br>
As one would expect, computer learning, or machine learning, as it
is called in the computing world, is a part of the growing
Artificial Intelligence field. While the biggest strides in the
field have only been made recently, the field itself has been
around for decades. The need for machine learning stems from the
complexity of modeling complex behavior. If AI can be thought of as
a set of rules for a computer to follow, then coming up with an AI
for a particular task would consist of coding those rules into a
program. But, what if the developer does not know all the rules?
What if there are too many rules to code? What if the rules are too
complex? What if we are not even sure what the rules are? These are
the problems that machine learning aims to solve. Most commonly,
this consists of transcribing the problem into a form that can be
tackled mathematically, coming up with a set of random rules, and
essentially using the trial and error method to gradually adjust
the rules until the number of errors is minimal.<br>
<br>
There are a multitude of different machine learning algorithms in
existence today, but the particular one that we have been
introduced to, and are working on implementing, is called Deep
Learning - a modern subset of Neural Networks made possible by teh
computing power of modern computers. This area of machine learning
is particularly interesting because it is modelled after the
workings of the brain. If you take an overarching look at the
brain's structure, you essentially end up with a multitude of cells
called neurons. These neurons take in a bunch of data, be it from
external sensors or other neurons, do some kind of processing on
that data, and either activate or not based on the processing they
do. Similarly, the fundamental part of a Neural Network is a nueron
- it accepts some input, performs a calculation on it, and outputs
either a 1 or a 0.</p>
